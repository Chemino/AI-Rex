{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd23b957-fa92-4dd0-ac8f-9f69e66a9893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAH0CAIAAABEtEjdAAAABmJLR0QA/wD/AP+gvaeTAAAcK0lEQVR4nO3dfVjV9f3H8c+Bo3KnIBjgDShyp5nTZooYlt0sFEO3CHJ5i9bSstmlTtOmW16VuoY3Td26tolJqIAilVnepM7LqXjLUtFduqkohjcQIuBRbs7vj7OdMWr9Ttz4Od83z8dfhy/fb76uo3t69uWAJqvVqgAAsrjoHgAAaHrEHQAEIu4AIBBxBwCBiDsACETcAUAg4g4AAhF3ABCIuAOAQMQdAAQi7gAgEHEHAIGIOwAIRNwBQCDiDgACEXcAEIi4A4BAxB0ABCLuACAQcQcAgYg7AAhE3AFAIOIOAAIRdwAQiLgDgEDEHQAEIu4AIBBxBwCBiDsACETcAUAg4g4AAhF3ABCIuAOAQMQdAAQi7gAgEHEHAIGIOwAIRNwBQCDiDgACEXcAEIi4A4BAxB0ABCLuACAQcQcAgYg7AAhE3AFAIOIOAAIRdwAQiLgDgEDEHQAEIu4AIBBxBwCBiDsACETcAUAg4g4AAhF3ABCIuAOAQMQdAAQi7gAgEHEHAIGIOwAIRNwBQCDiDgACEXcAEIi4A4BAxB0ABCLuACAQcQcAgYg7AAhE3AFAIOIOAAIRdwAQiLgDgEDEHQAEIu4AIBBxBwCBiDsACETcAUAg4g4AAhF3ABCIuAOAQMQdAAQi7gAgEHEHAIGIOwAIRNwBQCDiDgACEXcAEIi4A4BAxB0ABCLuACAQcQcAgYg7AAhE3AFAIOIOAAIRdwAQiLgDgEDEHQAEIu4AIBBxBwCBiDsACETcAUAg4g4AAhF3ABCIuAOAQMQdAAQi7gAgEHEHAIGIOwAIRNwBQCDiDgACEXcAEIi4A4BAxB0ABCLuACAQcQcAgYg7AAhE3AFAIOIOAAIRdwAQiLgDgEDEHQAEIu4AIBBxBwCBiDsACETcAUAg4g4AAhF3Z5GcnNzr34qLix28Kj093X5VRkZGsy50cqWlpfanYty4cY5fOG7cOPuFpaWlzbfQ+WVkZNifivT0dAevKi4utl+VnJzcrAvhOLPuAfiX8+fP5+fn2x5XV1c7eFVxcbH9qpKSkmZZZhDV1dX2p8LX19fxCxv2zItUUlJifyocf4VR95m/7777mmUZvj9euQOAQMQdAAQi7gAgEHEHAIGIOwAIRNwBQCDiDgACEXcAEIi4A4BAxB0ABOLHDzijoUOHms0O/dZcu3atuccYUV5eXv/+/R08+cyZM806xqBSUlLS0tIcObOF/8wGp0XcnVFeXp7uCcZWXl5+5MgR3SuMraCgoKCgQPcKNBy3ZQBAIF65O6PFixe3bdvWkTP37NmTmZnZ3HsMJzQ0dMaMGQ6enJKS8o9//KNZ9xhRUlLSkCFDHDnz1q1bs2fPbuY5+N6IuzMaP358QECAI2dWVVUR92/q2LHjlClTHDx53bp1xP2bHn74YQefw6tXrxJ3J8RtGQAQiLgDgEDEHQAEIu4AIBBxBwCBiDsACETcAUAg4g4AAhF3ABCIuAOAQMQdAATiZ8s4i0mTJj3xxBO2x15eXg5eFR0dvWDBAtvjAQMGNMsyg/D09LQ/FcHBwY5f+MILLzz11FP2/0jTLzOOAQMG2J/D6OhoB6/y8vKyX9WtW7fmGIYGMFmtVt0bAABNjNsyACAQcQcAgYi7MYwZM8bT0zMnJ0f3EAPz9PRs4bfUGyknJ8fT03PMmDG6h8AhfEHVGCwWS2VlJf8ScWNUVlbqnmBs1dXVlZWVFotF9xA4hFfuACAQcQcAgYg7AAhE3AFAIOIOAAIRdwAQiLgDgEDEHQAEIu4AIBBxBwCBiDsACETcAUAg4g4AAhF3ABCIuAOAQMQdAAQi7gAgEHEHAIGIOwAIRNwBQCDiDgACEXcAEIi4A4BAxB0ABCLuACAQcQcAgYg7AAhE3DU7f/785MmTQ0NDPTw8QkNDf/KTn+Tm5uoeZTzZ2dlxcXEBAQFubm7du3efMGFCfn6+7lGGcevWrblz5z744IPe3t7+/v6DBg1auXJlTU2N7l1oFOKu0759+/r165eamhoWFpaYmOjv75+TkxMTE7N161bd0wyjpqZm/PjxCQkJu3fvfvDBB0eNGhUWFpaZmXn79m3d04zBYrE88sgjCxcurKmpmThxYlJS0oULF6ZOnZqcnKx7GhrHCk1qamp69uzZsWPH06dP2w+uXLlSKfXAAw/UOzkhIUEplZWVdW83GsC7776rlOrTp09BQYH9YHl5+TfP5A/8t/rjH/+olBo8eHB1dbXtyI0bNwIDA5VSx44dq3tmVlaWUiohIUHHTHxvvHLXxsXFZfv27Tk5OT169LAfTE5ONplMttxr3GYUFovl7bffNpvNGzduDAoKsh/39PTUuMpYzpw5o5SKi4tzdXW1HfHz83vkkUeUUqdPn9a5DI1j1j2gRevSpUuXLl3qHrlw4YLVag0KCjKZTLpWGcj27dtLS0tjY2PDwsJ0bzEqf39/pdSRI0fqHiwoKFBKde/eXc8mNAVeuTuRS5cuTZ48WSk1Z84c3VuM4ejRo0qp3r17WyyWnJyct956a9myZfU6he+WlJTk4eGxadOmhIQE20v1zMzMgwcPDh8+fODAgbrXoeF45a5fRUXFyJEjCwsLz5075+3tnZaWNmbMGN2jjOHy5ctKqYsXL3bv3v2rr76yH09KSlq7dm2bNm30TTOMbt26ffzxx0lJSdnZ2dnZ2X379j1x4sTEiRNXrFihexoahVfu+plMJl9f344dOwYEBBQXF69Zs6Zup/AdysvLlVKbN28eMWLEX//614sXL27durVnz56ZmZm/+tWvdK8zhtra2s8//7y0tHTYsGFPPfXUiRMnampqPvnkk5ycHN3T0Di6v6KL/6iurra996Nfv361tbV1P8W7Zb7V2LFjlVK/+c1v6h603Vvw8fGxv/3Dhj/w3+rNN99USr344ou2D69cuTJv3rxWrVqZTKbNmzfXPZN3yxgLr9ydiKur68yZM3v06HH06NG//e1vuucYQIcOHZRSVVVVdQ/26NEjMDCwtLS0qKhI0y7DsFqtS5YscXFxWbhwoe1Ix44dFyxY8Oc//9lqtS5btkzvPDQGcXc6wcHBSinuzDiid+/eSqmTJ0/WPVhTU1NZWamUatu2rZ5ZxvH111/fvHnTy8vLz8+v7vHo6Gil1KVLlzTtQhMg7jplZGTs2LGj7pGysrLjx48r3oXmmLi4OLPZvHnz5mvXrtkPZmVllZWV9e3bt127dhq3GYK3t7e3t3dZWVleXl7d4/v371dKhYaGatqFJkDctamsrJwxY8bTTz89b968EydOXLlyZc+ePU8//fT169djY2MjIyN1DzSAgICAKVOmWCyW2NjYjIyMY8eOLVu2bNKkSSaTyXYrGd/N1dXV9u7bxMTEzz77rKKioqysLCMjY/r06SaT6bXXXtM9EI2g+6Z/i3bmzJn+/fvX+x0ZOnRocXFxvTP5gur/cufOnfHjx9d9Aj09PW23jOvhD/y3qqqqeuWVV1xc/ut1Xrt27VavXl3vTL6gaiy8z12nyMjI3NzcQ4cO5ebmlpSUdOjQISYmpm/fvrp3GUnr1q3XrFkzZ86cv/zlL2VlZUFBQUOHDvX29ta9yzDMZvOKFStmzZqVm5t7/vz56urqiIiIH/3oRzyHRkfcNTOZTFFRUVFRUbqHGFtkZCQ3shojODjY9pV8iME9dwAQiLgDgEDEHQAEIu4AIBBxBwCBiDsACETcAUAg4g4AAhF3ABCIuAOAQMQdAAQi7gAgEHEHAIGIOwAIRNwBQCDiDgACEXcAEIi4A4BAxB0ABCLuACAQcQcAgYg7AAhE3AFAIOIOAAIRdwAQiLgDgEDEHQAEIu5orEOHDj333HPh4eFdunR57LHHVq9ebbVadY8ynl27dsXHx0dFReXm5ureYiT5+fmh/9uXX36pe6A2Zt0DYGxZWVk//elPa2tro6Ki2rdvv3fv3j179uzevXvt2rUmk0n3OgOoqqrKyclJSUmxN/3y5ctRUVF6VxlI69atu3fv/s3jBw8eLC8vd3V1vfeTnARxR8PduHHjxRdfVEp99NFH8fHxSqnCwsIhQ4Z8+OGHw4cPHzVqlO6BBrBv375Ro0ZFRUUtWrTo2LFjmZmZuhcZTFhY2I4dO+odvHDhQnh4+EMPPdSrVy8tq5xB08T966+/Lioqsj0ODAxs3769I1dVV1efPXvW9tjT0zM4OLhJxuCeSU1NvXnzZnJysq3sSqnOnTsvXbo0Pj7+vffeI+6OGDJkSGFhYWBgoFJqxowZuucIsWzZsurq6l/84hf3/pcuKCioqKiwPQ4PDzebHWpswxL63Zrmnnt6evr9/7Zu3ToHr7p27Zr9quTk5CZZgntp27ZtSqmkpKS6B4cOHdquXbuDBw+WlpZq2mUkJpPJVnY0lbKystTU1K5duz7zzDP3/ldPTk62Z+3atWsOXrVu3Tr7Venp6U2yhC+oouFOnTqllIqIiKh70Gw2h4aGWq3W/Px8TbvQov3+978vKyt77bXXHHzVLBVxR8MVFxcrpfz9/esdtx2xfRa4l6qqqlauXNmuXTtuBhB3NJDVaq2urjaZTO7u7vU+5eHhoZS6c+eOjl1o0davX3/p0qWXXnrJ29tb9xbNiDsayJZ1q9VaUlJS71O21+xeXl46dqFFW7p0qdlsnjp1qu4h+hF3NFzXrl2VUlevXq133HbE9lngntm5c2deXl5SUhJvvVPEHY3Rr18/pdTBgwfrHrxx48bZs2d9fHzCw8M17UILlZKSopSaNm2a7iFOgbij4RITE5VSq1atqq6uth9ctWpVbW1tQkJCC3+vAu6xkydPbtu2bciQIQMGDNC9xSnwPz80XHx8fHR09IEDB55//vk333zTx8dnw4YNb731lqen59y5c3WvM4wTJ07YbmRdvHhRKfXll1/avhg4ePDgNm3aaB5nHEuWLLFarXwjmB1xR8OZTKZNmzaNGDEiKysrKyvLdtDPzy89Pf1bf9wHvtU777yzYcMG+4cLFiywPbh8+XLnzp01jTKYq1evrl+/PiIiIi4uTvcWZ0Hc0SgdO3Y8cODAF198cejQobt374aGho4cObJJvnm65Zg2bdq3fi+lr6/vvR9jUBaLZe3atRERES4u3Gr+l6aPe0lJie3/Xf6/HP/eXDgzs9kcGxsbGxure4hRDRw4cODAgbpXGFvXrl2d8N1ZhYWFVVVVjpz5zfcTN17Tx33+/Pnz589v8v8sABiL3i/tOuNtmbi4uM8++0z3Cmdke3cKGoOfMt9ImzZt4jmsZ9iwYVu3btW9oj7uTwGAQE3/yn3x4sUTJ0505MyrV68+8MAD3zzuhH8Havfss89u2rQpKyvr2Wef1b3FqGyvN/knABts48aNiYmJCQkJGzdu1L3FGE6ePBkQEODImatXr549e3bT/upNH3dPT88OHTo4cubdu3eb/FcHACfRvn17B2Po6enZ5L+6M95zv8eKi4sPHz5cVFTUoUOH6OhoPz8/3YsAoLFadNzv3r07a9as999/32Kx2I64u7vPnz//9ddf1zsMABqpRX9BdezYscuXL+/fv39GRsbevXtTUlJatWo1Z86ctWvX6p4GAI3Scl+5l5aWXrhwITY2dsuWLbYfcTV48GB/f/+xY8cuXbp03LhxugcCQMO13Lj7+Pjk5uZaLJa6P7wwPj5eKXXq1Cmr1cqbeQEYV4u+LaOUcnNzq/uh2Ww2mUz8eAoARkfF/suRI0esVmufPn142Q7A0Ij7f1m6dKlSasKECbqHAECjEPf/WLNmzUcffdSnT59Jkybp3gIAjULc/+XTTz+dPHly586dN23a1Lp1a91zAKBRiLtSSqWlpSUkJHh7e+/cuTM0NFT3HABorKZ5K+To0aOfeOIJ2+PAwEAHr/L398/Pz7c9bo4freCIu3fvTp8+feXKlT169MjJyYmMjNQyA4AMqampFRUVtsf+/v4OXvX8888//vjjtseOJ/S7NU3c27dv34B/Wc1sNvfs2bNJBjRMYWFhYmLigQMH4uLi0tPTfXx8NI4BIEBwcHADrmpYQr9by/0mprNnz8bExFy7ds3Nzc3d3f1nP/tZ3c/Onz//W38cMQAYQsuN+6VLl6qqqmx/W+7ataveZ6dOnapjFAA0jZYb98cff7w5/lFaAHAGvFsGAAQi7gAgEHEHAIGIOwAIRNwBQCDiDgACEXcAEIi4A4BAxB0ABCLuACAQcQcAgYg7AAhE3AFAIOIOAAIRdwAQiLgDgEDEHQAEIu4AIBBxBwCBiDsACETcAUAg4g4AAhF3ABCIuAOAQMQdAAQi7gAgEHEHAIHMugegydy8efPw4cNKKQ8Pj0GDBumeYxj5+flXrlypdzAgIKB3795a9hhURUXF8ePHS0tLg4KCfvCDH5hMJt2LWjriLserr76alpamlIqMjDxz5ozuOYYxb9687OzsegdfeeWVFStWaNljOLW1tYsXL160aFFZWZntSERERGpqKq8w9CLuQmzbti0tLS0uLm7r1q26txjMV199ZTKZ1q9f7+Lyn7uU999/v8ZJxvLLX/5y4cKFAQEBb7zxhr+///79+1NTU2NjY48cORIZGal7XctF3CWorKx8+eWX27Ztu2zZMuL+fV25csXPz++5557TPcSQCgsL3333XXd3971790ZERCilJkyYEBISMnfu3Pnz52dkZOge2HLxBVUJ5s6d+89//vPtt9/u0qWL7i0GY7Vai4qKOnXqpHuIUe3cubO6unrEiBG2sttMmTLFzc3tk08+sVgsGre1cMTd8A4dOrRixYqHHnro5Zdf1r3FeIqLi+/cuUPcG6ykpEQpFRgYWPegj49PWFjY7du38/PzNe0CcTe46urql156SSn1/vvvu7q66p5jPEVFRUqpwsLC4cOHBwUFderUKTY2dsuWLbp3GUbXrl2VUsePH693PCAgQCn1zbch4Z4h7sb2zjvv5OXlTZs27Yc//KHuLYbk4uISEBBQWlrarl27+Pj4Xr167dy5Mz4+fuHChbqnGcOwYcP8/f337t27YMGCiooKpdTp06cnTZr0xRdfKKVu376te2ALZoURJCQkKKWysrLqHjxz5oybm1tQUNCtW7dsRyorK5VSkZGROjY6u//1B/7u3bt1P9y3b1+bNm1cXFzOnTt3r6YZQ1ZWllIqISGh3vFdu3b5+PgopUwmk7u7u1IqJCTEdgv+008/1TIVVquVV+5GVVtb+8ILL1gslt/97ndeXl665xhYq1at6n748MMPjx49ura29uOPP9Y1yVgee+yxU6dOLVy4cMyYMaNHj05NTbXfaq93Lx73Em+FNKotW7bs27dPKZWcnGw/aLValVLnzp3z9fWdOnXqggULtO0zspCQEKXU9evXdQ8xjE6dOr3++uv2Dy0Wy/nz51u3bt2rVy+Nq1o44m5Uvr6+iYmJ9Q7W1NRkZ2d7eHg8+eST4eHhWoYJ8Pe//10pFRwcrHuIUWVmZlZVVf34xz9u06aN7i0tF3E3qpiYmJiYmHoHb9++7eHh0alTp8zMTC2rDOfDDz9MS0tbvXp1586dbUd27ty5YcMGd3f3Z555Ru82gzp9+vTs2bNdXFxmzZqle0uLRtzRom3fvn379u3h4eFPPvlk165dz549u337dhcXlz/96U/+/v661xnDihUrMjIyHnnkEQ8Pj/z8/OzsbIvFsmjRoujoaN3TWjTiLorJZGrfvn27du10DzGMDz74YOTIkatWrdqxY4fFYvHw8IiPj3/jjTcGDBige5ph3Llz59y5c7avALm6ukZHR8+dO3fYsGG6d7V0xF0UNzc323cMwkEmkykhIcH2TtOysjL+XmyAGTNmzJgxo7i4uLy8/L777vPw8NC9CEoRd8COsjeGn5+fn5+f7hX4D97nDgACEXcAEIi4A4BAxB0ABCLuACAQcQcAgYg7AAhE3AFAIOIOAAIRdwAQiLgDgEDEHQAEIu4AIBBxBwCBiDsACETcAUAg4g4AAhF3ABCIuAOAQMQdAAQi7gAgEHEHAIGIOwAIRNwBQCDiDgACEXcAEMisewAc4ubm5uHhYTbz+9VwHh4euicYm9ls9vDwcHNz0z0EDjFZrVbdGwAATYzbMgAgEHEHAIG4h+ss0tLSLly4YHs8ffp0T09PR646fPjw559/bnscFxfXr1+/Zprn/G7fvv3b3/7W9jg4OHj8+PEOXvjBBx8UFBTYHs+cOdPd3b1Z9hnB0aNHt27dans8dOjQ/v37O3JVRUXFkiVLbI+7des2duzY5tqH78UK5/Doo4/af1OKioocvGr58uX2q1atWtWsC53c9evX7U9FTEyM4xfGxMTYL7x+/XrzLXR+q1atsj8Vy5cvd/CqoqIi+1WPPvpocw7E98BtGQAQiLgDgEDEHQAEIu4AIBBxBwCBiDsACETcAUAg4g4AAhF3ABCIuAOAQPxsGWf0hz/8wcvLy5Ez9+3b19xjjKiwsDAlJcXxk5t1jEHt3r27qqrKkTPLy8ubewwagLg7o1//+te6Jxjb+fPnZ86cqXuFseXk5OTk5OhegYbjtgwACMQrd2c0aNCgVq1aOXJmYWHhuXPnmnuP4Xh7e/ft29fBk/Py8m7evNmse4woLCysc+fOjpxZVVW1f//+5t6D74u4O6Ps7OyAgABHznzvvfemTZvW3HsMp3fv3nv27HHw5MGDB/Oli2969dVXf/7znzty5tWrVwMDA5t7D74vbssAgEDEHQAEIu4AIBBxBwCBiDsACETcAUAg4g4AAhF3ABCIuAOAQMQdAAQi7gAgED9bxlmEhIRcv37d9thsdvT3xc/P7/7777c99vX1bZZlBmE2m+1PRUhIiOMXhoSElJSU2P8jTb/MOHx9fe3PoZ+fn4NXNfiZR7MyWa1W3RsAAE2M2zIAIBBxBwCBiDsACETcAUAg4g4AAhF3ABCIuAOAQMQdAAQi7gAgEHEHAIGIOwAIRNwBQCDiDgACEXcAEIi4A4BAxB0ABCLuACAQcQcAgYg7AAhE3AFAIOIOAAIRdwAQiLgDgEDEHQAEIu4AIBBxBwCBiDsACETcAUAg4g4AAhF3ABCIuAOAQMQdAAQi7gAgEHEHAIGIOwAIRNwBQCDiDgACEXcAEIi4A4BAxB0ABCLuACAQcQcAgYg7AAhE3AFAIOIOAAIRdwAQiLgDgEDEHQAEIu4AIBBxBwCBiDsACETcAUAg4g4AAhF3ABCIuAOAQMQdAAQi7gAgEHEHAIGIOwAIRNwBQCDiDgACEXcAEIi4A4BAxB0ABCLuACAQcQcAgYg7AAhE3AFAIOIOAAIRdwAQiLgDgEDEHQAEIu4AIBBxBwCBiDsACETcAUAg4g4AAhF3ABCIuAOAQMQdAAQi7gAgEHEHAIGIOwAIRNwBQCDiDgACEXcAEIi4A4BAxB0ABCLuACAQcQcAgYg7AAhE3AFAIOIOAAIRdwAQiLgDgEDEHQAEIu4AIBBxBwCBiDsACETcAUAg4g4AAhF3ABCIuAOAQMQdAAQi7gAgEHEHAIGIOwAIRNwBQCDiDgACEXcAEIi4A4BAxB0ABCLuACAQcQcAgYg7AAhE3AFAIOIOAAIRdwAQiLgDgEDEHQAEIu4AIBBxBwCBiDsACETcAUAg4g4AAhF3ABCIuAOAQP8Hya47sF4+DH4AAACeelRYdHJka2l0UEtMIHJka2l0IDIwMjIuMDMuMgAAeJx7v2/tPQYg4GWAAEYg5gZiLiBuYGRTSADSLMxQmgnGZ2TQACsml+YG2sPIxMDADDSMgYGVgZGNgZGdgYmDgYmTgYmLQYRBvA/qFjAAOujA/h69XYthAgj2AXsE2+HAz2YbVaj4fpAcEns/AxzA2A2qCDUODshmIum1h6kXAwChQyNLA1NJGQAAAPR6VFh0TU9MIHJka2l0IDIwMjIuMDMuMgAAeJyNkkkOgzAMRfc5xb8AKCFMWTKpVBUgtbR36L73V20QOAgpwmFhOy+W7Y8C27N9fH/YLWmVAnTgc87hY7XWagA7qLvbfUQzV/WWaab3OL9gDIzGco5sNU/DljFoEJk402yIdKxXT5yNTIjcsyHQEnipYooekT3fn8CMwb3k7pzB/ABGAbIgUqYJgKUPBjhHnL2yHtKkx5VhSD8PDPXYje1B1FXmehpbkZlPIlpSACuK8W0qunCYyfY5zGXH/LaQRXJYyroMlXOyFQ6NP/ySMH7rfqMcb/8y+eoPVMKUrLz7lMMAAACBelRYdFNNSUxFUyByZGtpdCAyMDIyLjAzLjIAAHici/aIddaI9ojVBBPYmUCsUKOha6xjoGOta6hnCqdBGMICE9YGIBkDOAdMQdWDNcP1wLVo6iSW5OcGFOUXWBnoZRZ75hbkZCZnlugZWhmhco1RuaaoXDNUrgUq1xKVa4hqUw0AY7FIgCW5LN4AAAAASUVORK5CYII=",
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x7efd46962c60>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import Draw\n",
    "IPythonConsole.drawOptions.addBondIndices = True\n",
    "IPythonConsole.molSize = 500,500\n",
    "\n",
    "smiles = r\"CCC\"\n",
    "mol = Chem.MolFromSmiles(smiles)\n",
    "mol = Chem.AddHs(mol)\n",
    "mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3101249c-03e4-40ea-a15c-6abf17c6e415",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-21 18:45:19.579616: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-21 18:45:21.007598: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-21 18:45:21.007634: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: S03-SIAI\n",
      "2022-05-21 18:45:21.007640: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: S03-SIAI\n",
      "2022-05-21 18:45:21.007727: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2022-05-21 18:45:21.007754: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.73.5\n",
      "2022-05-21 18:45:21.007987: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from modify_rrd import RRDCalculator\n",
    "RRDC = RRDCalculator(scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fc6448-2c3b-4cae-a8fa-a3ee8ebd8da0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 单个计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2173e33-92a2-4d1d-b9b8-9d155d8815a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "dfa, dfb = RRDC.transform(smiles) ## atom and bond features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78e4750d-5a2a-40ed-be00-bb9d965683bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC</th>\n",
       "      <th>FN</th>\n",
       "      <th>FE</th>\n",
       "      <th>NSC</th>\n",
       "      <th>GC</th>\n",
       "      <th>MR</th>\n",
       "      <th>APol</th>\n",
       "      <th>SHI</th>\n",
       "      <th>TSEI</th>\n",
       "      <th>0</th>\n",
       "      <th>...</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AtomIdx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.329121</td>\n",
       "      <td>0.205732</td>\n",
       "      <td>0.215768</td>\n",
       "      <td>0.634038</td>\n",
       "      <td>0.543116</td>\n",
       "      <td>0.178531</td>\n",
       "      <td>0.119785</td>\n",
       "      <td>0.169843</td>\n",
       "      <td>0.399595</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.368397</td>\n",
       "      <td>0.208627</td>\n",
       "      <td>0.211112</td>\n",
       "      <td>0.632164</td>\n",
       "      <td>0.547651</td>\n",
       "      <td>0.178531</td>\n",
       "      <td>0.119785</td>\n",
       "      <td>0.212078</td>\n",
       "      <td>0.460438</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.329121</td>\n",
       "      <td>0.205732</td>\n",
       "      <td>0.215768</td>\n",
       "      <td>0.634038</td>\n",
       "      <td>0.543116</td>\n",
       "      <td>0.178531</td>\n",
       "      <td>0.119785</td>\n",
       "      <td>0.169843</td>\n",
       "      <td>0.149643</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.430393</td>\n",
       "      <td>0.175945</td>\n",
       "      <td>0.242508</td>\n",
       "      <td>0.475004</td>\n",
       "      <td>0.603977</td>\n",
       "      <td>0.075392</td>\n",
       "      <td>0.010932</td>\n",
       "      <td>0.214501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.430393</td>\n",
       "      <td>0.175945</td>\n",
       "      <td>0.242508</td>\n",
       "      <td>0.475004</td>\n",
       "      <td>0.603977</td>\n",
       "      <td>0.075392</td>\n",
       "      <td>0.010932</td>\n",
       "      <td>0.214501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.430393</td>\n",
       "      <td>0.175945</td>\n",
       "      <td>0.242508</td>\n",
       "      <td>0.475004</td>\n",
       "      <td>0.603977</td>\n",
       "      <td>0.075392</td>\n",
       "      <td>0.010932</td>\n",
       "      <td>0.203784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.429255</td>\n",
       "      <td>0.233265</td>\n",
       "      <td>0.254574</td>\n",
       "      <td>0.474885</td>\n",
       "      <td>0.606080</td>\n",
       "      <td>0.075392</td>\n",
       "      <td>0.010932</td>\n",
       "      <td>0.230402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.429255</td>\n",
       "      <td>0.233265</td>\n",
       "      <td>0.254574</td>\n",
       "      <td>0.474885</td>\n",
       "      <td>0.606080</td>\n",
       "      <td>0.075392</td>\n",
       "      <td>0.010932</td>\n",
       "      <td>0.230402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.430393</td>\n",
       "      <td>0.175945</td>\n",
       "      <td>0.242508</td>\n",
       "      <td>0.475004</td>\n",
       "      <td>0.603977</td>\n",
       "      <td>0.075392</td>\n",
       "      <td>0.010932</td>\n",
       "      <td>0.214501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.430393</td>\n",
       "      <td>0.175945</td>\n",
       "      <td>0.242508</td>\n",
       "      <td>0.475004</td>\n",
       "      <td>0.603977</td>\n",
       "      <td>0.075392</td>\n",
       "      <td>0.010932</td>\n",
       "      <td>0.203784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.430393</td>\n",
       "      <td>0.175945</td>\n",
       "      <td>0.242508</td>\n",
       "      <td>0.475004</td>\n",
       "      <td>0.603977</td>\n",
       "      <td>0.075392</td>\n",
       "      <td>0.010932</td>\n",
       "      <td>0.214501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               PC        FN        FE       NSC        GC        MR      APol  \\\n",
       "AtomIdx                                                                         \n",
       "0        0.329121  0.205732  0.215768  0.634038  0.543116  0.178531  0.119785   \n",
       "1        0.368397  0.208627  0.211112  0.632164  0.547651  0.178531  0.119785   \n",
       "2        0.329121  0.205732  0.215768  0.634038  0.543116  0.178531  0.119785   \n",
       "3        0.430393  0.175945  0.242508  0.475004  0.603977  0.075392  0.010932   \n",
       "4        0.430393  0.175945  0.242508  0.475004  0.603977  0.075392  0.010932   \n",
       "5        0.430393  0.175945  0.242508  0.475004  0.603977  0.075392  0.010932   \n",
       "6        0.429255  0.233265  0.254574  0.474885  0.606080  0.075392  0.010932   \n",
       "7        0.429255  0.233265  0.254574  0.474885  0.606080  0.075392  0.010932   \n",
       "8        0.430393  0.175945  0.242508  0.475004  0.603977  0.075392  0.010932   \n",
       "9        0.430393  0.175945  0.242508  0.475004  0.603977  0.075392  0.010932   \n",
       "10       0.430393  0.175945  0.242508  0.475004  0.603977  0.075392  0.010932   \n",
       "\n",
       "              SHI      TSEI  0  ...  8  9  10  11  12  13  14  15  16  17  \n",
       "AtomIdx                         ...                                        \n",
       "0        0.169843  0.399595  0  ...  0  0   0   0   0   0   0   0   0   0  \n",
       "1        0.212078  0.460438  0  ...  0  0   0   0   0   0   0   0   0   0  \n",
       "2        0.169843  0.149643  0  ...  0  0   0   0   0   0   0   0   0   0  \n",
       "3        0.214501  0.000000  1  ...  0  0   0   0   0   0   0   0   0   0  \n",
       "4        0.214501  0.000000  1  ...  0  0   0   0   0   0   0   0   0   0  \n",
       "5        0.203784  0.000000  1  ...  0  0   0   0   0   0   0   0   0   0  \n",
       "6        0.230402  0.000000  1  ...  0  0   0   0   0   0   0   0   0   0  \n",
       "7        0.230402  0.000000  1  ...  0  0   0   0   0   0   0   0   0   0  \n",
       "8        0.214501  0.000000  1  ...  0  0   0   0   0   0   0   0   0   0  \n",
       "9        0.203784  0.000000  1  ...  0  0   0   0   0   0   0   0   0   0  \n",
       "10       0.214501  0.000000  1  ...  0  0   0   0   0   0   0   0   0   0  \n",
       "\n",
       "[11 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab2d8607-45e9-4b3f-8c49-6e4c1e28f10d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SB</th>\n",
       "      <th>DB</th>\n",
       "      <th>TB</th>\n",
       "      <th>AB</th>\n",
       "      <th>CB</th>\n",
       "      <th>RB</th>\n",
       "      <th>SN</th>\n",
       "      <th>SA</th>\n",
       "      <th>SS</th>\n",
       "      <th>SR</th>\n",
       "      <th>BO</th>\n",
       "      <th>BL</th>\n",
       "      <th>BDE</th>\n",
       "      <th>BDFE</th>\n",
       "      <th>BeginAtomIdx</th>\n",
       "      <th>EndAtomIdx</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BondIdx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209400</td>\n",
       "      <td>0.427884</td>\n",
       "      <td>0.326613</td>\n",
       "      <td>0.306577</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209438</td>\n",
       "      <td>0.427833</td>\n",
       "      <td>0.326613</td>\n",
       "      <td>0.306577</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172765</td>\n",
       "      <td>0.099385</td>\n",
       "      <td>0.394351</td>\n",
       "      <td>0.395220</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172765</td>\n",
       "      <td>0.099385</td>\n",
       "      <td>0.394351</td>\n",
       "      <td>0.395220</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172765</td>\n",
       "      <td>0.099385</td>\n",
       "      <td>0.394351</td>\n",
       "      <td>0.395220</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.165201</td>\n",
       "      <td>0.102334</td>\n",
       "      <td>0.372077</td>\n",
       "      <td>0.372929</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.165201</td>\n",
       "      <td>0.102334</td>\n",
       "      <td>0.372077</td>\n",
       "      <td>0.372929</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172765</td>\n",
       "      <td>0.099385</td>\n",
       "      <td>0.394351</td>\n",
       "      <td>0.395220</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172765</td>\n",
       "      <td>0.099385</td>\n",
       "      <td>0.394351</td>\n",
       "      <td>0.395220</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172765</td>\n",
       "      <td>0.099385</td>\n",
       "      <td>0.394351</td>\n",
       "      <td>0.395220</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SB   DB   TB   AB   CB   RB   SN   SA   SS   SR        BO        BL  \\\n",
       "BondIdx                                                                         \n",
       "0        1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.209400  0.427884   \n",
       "1        1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.209438  0.427833   \n",
       "2        1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.172765  0.099385   \n",
       "3        1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.172765  0.099385   \n",
       "4        1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.172765  0.099385   \n",
       "5        1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.165201  0.102334   \n",
       "6        1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.165201  0.102334   \n",
       "7        1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.172765  0.099385   \n",
       "8        1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.172765  0.099385   \n",
       "9        1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.172765  0.099385   \n",
       "\n",
       "              BDE      BDFE  BeginAtomIdx  EndAtomIdx  \n",
       "BondIdx                                                \n",
       "0        0.326613  0.306577             1           0  \n",
       "1        0.326613  0.306577             2           1  \n",
       "2        0.394351  0.395220             3           0  \n",
       "3        0.394351  0.395220             4           0  \n",
       "4        0.394351  0.395220             5           0  \n",
       "5        0.372077  0.372929             6           1  \n",
       "6        0.372077  0.372929             7           1  \n",
       "7        0.394351  0.395220             8           2  \n",
       "8        0.394351  0.395220             9           2  \n",
       "9        0.394351  0.395220            10           2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fad533d-11f6-4e30-9420-20aed909c586",
   "metadata": {},
   "source": [
    "# 批量计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cf10c90-ae3f-41f9-a1f0-a1faab254ad2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 20/20 [00:00<00:00, 620.81it/s]\n",
      "2022-05-21 18:52:54.083520: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-21 18:52:54.103133: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-21 18:52:54.126728: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-21 18:52:54.131483: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-21 18:52:54.168232: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-21 18:52:54.168232: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-21 18:52:54.179901: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-21 18:52:54.192149: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-21 18:52:54.192149: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-21 18:52:54.192151: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-21 18:52:54.193123: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-21 18:52:54.193125: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-21 18:52:54.193124: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-21 18:52:54.216998: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-21 18:52:54.216999: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-21 18:52:54.233315: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-21 18:52:54.319567: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-21 18:52:54.344329: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-21 18:52:54.372843: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-21 18:52:54.503795: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-21 18:52:55.534474: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-21 18:52:55.534519: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: S03-SIAI\n",
      "2022-05-21 18:52:55.534526: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: S03-SIAI\n",
      "2022-05-21 18:52:55.534637: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2022-05-21 18:52:55.534665: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.73.5\n",
      "2022-05-21 18:52:55.534918: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-21 18:52:55.570551: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-21 18:52:55.570591: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: S03-SIAI\n",
      "2022-05-21 18:52:55.570598: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: S03-SIAI\n",
      "2022-05-21 18:52:55.570711: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2022-05-21 18:52:55.570744: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.73.5\n",
      "2022-05-21 18:52:55.571000: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-21 18:52:55.574345: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-21 18:52:55.574394: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: S03-SIAI\n",
      "2022-05-21 18:52:55.574403: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: S03-SIAI\n",
      "2022-05-21 18:52:55.574531: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2022-05-21 18:52:55.574576: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.73.5\n",
      "2022-05-21 18:52:55.574909: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-21 18:52:55.607447: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-21 18:52:55.607446: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-21 18:52:55.607500: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: S03-SIAI\n",
      "2022-05-21 18:52:55.607500: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: S03-SIAI\n",
      "2022-05-21 18:52:55.607507: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: S03-SIAI\n",
      "2022-05-21 18:52:55.607507: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: S03-SIAI\n",
      "2022-05-21 18:52:55.607624: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2022-05-21 18:52:55.607624: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2022-05-21 18:52:55.607665: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.73.5\n",
      "2022-05-21 18:52:55.607665: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.73.5\n",
      "2022-05-21 18:52:55.607956: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-21 18:52:55.607956: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-21 18:52:55.636248: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-21 18:52:55.636290: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: S03-SIAI\n",
      "2022-05-21 18:52:55.636297: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: S03-SIAI\n",
      "2022-05-21 18:52:55.636407: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2022-05-21 18:52:55.636443: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.73.5\n",
      "2022-05-21 18:52:55.636698: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-21 18:52:55.640715: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-21 18:52:55.640762: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: S03-SIAI\n",
      "2022-05-21 18:52:55.640769: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: S03-SIAI\n",
      "2022-05-21 18:52:55.640879: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2022-05-21 18:52:55.640911: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.73.5\n",
      "2022-05-21 18:52:55.641172: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-21 18:52:55.650426: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-21 18:52:55.650471: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: S03-SIAI\n",
      "2022-05-21 18:52:55.650478: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: S03-SIAI\n",
      "2022-05-21 18:52:55.650593: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2022-05-21 18:52:55.650624: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.73.5\n",
      "2022-05-21 18:52:55.650928: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-21 18:52:55.667558: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-21 18:52:55.667624: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: S03-SIAI\n",
      "2022-05-21 18:52:55.667635: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: S03-SIAI\n",
      "2022-05-21 18:52:55.667812: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2022-05-21 18:52:55.667863: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.73.5\n",
      "2022-05-21 18:52:55.668271: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-21 18:52:55.675394: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-21 18:52:55.675451: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: S03-SIAI\n",
      "2022-05-21 18:52:55.675459: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: S03-SIAI\n",
      "2022-05-21 18:52:55.675638: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2022-05-21 18:52:55.675684: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.73.5\n",
      "2022-05-21 18:52:55.675701: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-21 18:52:55.675746: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: S03-SIAI\n",
      "2022-05-21 18:52:55.675760: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: S03-SIAI\n",
      "2022-05-21 18:52:55.675905: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2022-05-21 18:52:55.675956: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.73.5\n",
      "2022-05-21 18:52:55.676096: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-21 18:52:55.676477: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-21 18:52:55.684539: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-21 18:52:55.684587: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: S03-SIAI\n",
      "2022-05-21 18:52:55.684600: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: S03-SIAI\n",
      "2022-05-21 18:52:55.684716: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2022-05-21 18:52:55.684753: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.73.5\n",
      "2022-05-21 18:52:55.685173: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-21 18:52:55.739936: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-21 18:52:55.739985: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: S03-SIAI\n",
      "2022-05-21 18:52:55.739992: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: S03-SIAI\n",
      "2022-05-21 18:52:55.740111: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2022-05-21 18:52:55.740145: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.73.5\n",
      "2022-05-21 18:52:55.740512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-21 18:52:55.747872: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-21 18:52:55.748105: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: S03-SIAI\n",
      "2022-05-21 18:52:55.748135: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: S03-SIAI\n",
      "2022-05-21 18:52:55.748327: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2022-05-21 18:52:55.748407: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.73.5\n",
      "2022-05-21 18:52:55.749184: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-21 18:52:55.751600: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-21 18:52:55.751635: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: S03-SIAI\n",
      "2022-05-21 18:52:55.751641: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: S03-SIAI\n",
      "2022-05-21 18:52:55.751755: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2022-05-21 18:52:55.751787: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.73.5\n",
      "2022-05-21 18:52:55.752043: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-21 18:52:55.757912: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-21 18:52:55.757959: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: S03-SIAI\n",
      "2022-05-21 18:52:55.757966: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: S03-SIAI\n",
      "2022-05-21 18:52:55.758081: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2022-05-21 18:52:55.758120: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.73.5\n",
      "2022-05-21 18:52:55.758390: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-21 18:52:55.767904: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-21 18:52:55.767955: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: S03-SIAI\n",
      "2022-05-21 18:52:55.767965: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: S03-SIAI\n",
      "2022-05-21 18:52:55.768099: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2022-05-21 18:52:55.768146: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.73.5\n",
      "2022-05-21 18:52:55.768545: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-21 18:52:55.772357: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-21 18:52:55.772402: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: S03-SIAI\n",
      "2022-05-21 18:52:55.772408: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: S03-SIAI\n",
      "2022-05-21 18:52:55.772526: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2022-05-21 18:52:55.772562: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.73.5\n",
      "2022-05-21 18:52:55.772857: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-21 18:52:55.844409: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-21 18:52:55.844455: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: S03-SIAI\n",
      "2022-05-21 18:52:55.844461: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: S03-SIAI\n",
      "2022-05-21 18:52:55.844575: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2022-05-21 18:52:55.844611: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.73.5\n",
      "2022-05-21 18:52:55.844890: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-21 18:52:55.946015: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-21 18:52:55.946058: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: S03-SIAI\n",
      "2022-05-21 18:52:55.946064: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: S03-SIAI\n",
      "2022-05-21 18:52:55.946177: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2022-05-21 18:52:55.946211: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.73.5\n",
      "2022-05-21 18:52:55.946483: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "      1/Unknown - 1s 1s/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-21 18:53:02.795988: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-05-21 18:53:02.874874: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-05-21 18:53:02.896150: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-05-21 18:53:02.918045: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-21 18:53:03.016404: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-05-21 18:53:03.039424: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-05-21 18:53:03.131173: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-05-21 18:53:03.195517: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-21 18:53:03.263427: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-05-21 18:53:03.442596: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "smiles_list = [smiles for i in range(20)]\n",
    "res = RRDC.batch_transform(smiles_list, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8e682de-f2e4-4d7f-b9f5-8790d6dfcc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "atoms = np.array([0] + [20 for _ in range(20)])\n",
    "atom_cumsum = atoms.cumsum().tolist()[:-1]\n",
    "\n",
    "edges_src = [df[1].BeginAtomIdx.values.astype(int) for df in res]\n",
    "edges_dst = [df[1].EndAtomIdx.values.astype(int) for df in res]\n",
    "\n",
    "edges_src = [edges_src[i] + atom_cumsum[i] for i in range(len(atom_cumsum))]\n",
    "edges_dst= [edges_dst[i] + atom_cumsum[i] for i in range(len(atom_cumsum))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0197191a-f968-45db-bf2a-7f578862b5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  21,  22,  23,\n",
       "        24,  25,  26,  27,  28,  29,  30,  41,  42,  43,  44,  45,  46,\n",
       "        47,  48,  49,  50,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
       "        70,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90, 101, 102,\n",
       "       103, 104, 105, 106, 107, 108, 109, 110, 121, 122, 123, 124, 125,\n",
       "       126, 127, 128, 129, 130, 141, 142, 143, 144, 145, 146, 147, 148,\n",
       "       149, 150, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 201, 202, 203, 204,\n",
       "       205, 206, 207, 208, 209, 210, 221, 222, 223, 224, 225, 226, 227,\n",
       "       228, 229, 230, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250,\n",
       "       261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 281, 282, 283,\n",
       "       284, 285, 286, 287, 288, 289, 290, 301, 302, 303, 304, 305, 306,\n",
       "       307, 308, 309, 310, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
       "       330, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 361, 362,\n",
       "       363, 364, 365, 366, 367, 368, 369, 370, 381, 382, 383, 384, 385,\n",
       "       386, 387, 388, 389, 390])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_src = np.concatenate(edges_src)\n",
    "edges_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25d98f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC</th>\n",
       "      <th>FN</th>\n",
       "      <th>FE</th>\n",
       "      <th>NSC</th>\n",
       "      <th>GC</th>\n",
       "      <th>MR</th>\n",
       "      <th>APol</th>\n",
       "      <th>SHI</th>\n",
       "      <th>TSEI</th>\n",
       "      <th>0</th>\n",
       "      <th>...</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AtomIdx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.329121</td>\n",
       "      <td>0.205732</td>\n",
       "      <td>0.215768</td>\n",
       "      <td>0.634038</td>\n",
       "      <td>0.543116</td>\n",
       "      <td>0.178531</td>\n",
       "      <td>0.119785</td>\n",
       "      <td>0.169843</td>\n",
       "      <td>0.399595</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.368397</td>\n",
       "      <td>0.208627</td>\n",
       "      <td>0.211112</td>\n",
       "      <td>0.632164</td>\n",
       "      <td>0.547651</td>\n",
       "      <td>0.178531</td>\n",
       "      <td>0.119785</td>\n",
       "      <td>0.212078</td>\n",
       "      <td>0.460438</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.329121</td>\n",
       "      <td>0.205732</td>\n",
       "      <td>0.215768</td>\n",
       "      <td>0.634038</td>\n",
       "      <td>0.543116</td>\n",
       "      <td>0.178531</td>\n",
       "      <td>0.119785</td>\n",
       "      <td>0.169843</td>\n",
       "      <td>0.149643</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.430393</td>\n",
       "      <td>0.175945</td>\n",
       "      <td>0.242508</td>\n",
       "      <td>0.475004</td>\n",
       "      <td>0.603977</td>\n",
       "      <td>0.075392</td>\n",
       "      <td>0.010932</td>\n",
       "      <td>0.214501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.430393</td>\n",
       "      <td>0.175945</td>\n",
       "      <td>0.242508</td>\n",
       "      <td>0.475004</td>\n",
       "      <td>0.603977</td>\n",
       "      <td>0.075392</td>\n",
       "      <td>0.010932</td>\n",
       "      <td>0.214501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.430393</td>\n",
       "      <td>0.175945</td>\n",
       "      <td>0.242508</td>\n",
       "      <td>0.475004</td>\n",
       "      <td>0.603977</td>\n",
       "      <td>0.075392</td>\n",
       "      <td>0.010932</td>\n",
       "      <td>0.203784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.429255</td>\n",
       "      <td>0.233265</td>\n",
       "      <td>0.254574</td>\n",
       "      <td>0.474885</td>\n",
       "      <td>0.606080</td>\n",
       "      <td>0.075392</td>\n",
       "      <td>0.010932</td>\n",
       "      <td>0.230402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.429255</td>\n",
       "      <td>0.233265</td>\n",
       "      <td>0.254574</td>\n",
       "      <td>0.474885</td>\n",
       "      <td>0.606080</td>\n",
       "      <td>0.075392</td>\n",
       "      <td>0.010932</td>\n",
       "      <td>0.230402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.430393</td>\n",
       "      <td>0.175945</td>\n",
       "      <td>0.242508</td>\n",
       "      <td>0.475004</td>\n",
       "      <td>0.603977</td>\n",
       "      <td>0.075392</td>\n",
       "      <td>0.010932</td>\n",
       "      <td>0.214501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.430393</td>\n",
       "      <td>0.175945</td>\n",
       "      <td>0.242508</td>\n",
       "      <td>0.475004</td>\n",
       "      <td>0.603977</td>\n",
       "      <td>0.075392</td>\n",
       "      <td>0.010932</td>\n",
       "      <td>0.203784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.430393</td>\n",
       "      <td>0.175945</td>\n",
       "      <td>0.242508</td>\n",
       "      <td>0.475004</td>\n",
       "      <td>0.603977</td>\n",
       "      <td>0.075392</td>\n",
       "      <td>0.010932</td>\n",
       "      <td>0.214501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               PC        FN        FE       NSC        GC        MR      APol  \\\n",
       "AtomIdx                                                                         \n",
       "0        0.329121  0.205732  0.215768  0.634038  0.543116  0.178531  0.119785   \n",
       "1        0.368397  0.208627  0.211112  0.632164  0.547651  0.178531  0.119785   \n",
       "2        0.329121  0.205732  0.215768  0.634038  0.543116  0.178531  0.119785   \n",
       "3        0.430393  0.175945  0.242508  0.475004  0.603977  0.075392  0.010932   \n",
       "4        0.430393  0.175945  0.242508  0.475004  0.603977  0.075392  0.010932   \n",
       "5        0.430393  0.175945  0.242508  0.475004  0.603977  0.075392  0.010932   \n",
       "6        0.429255  0.233265  0.254574  0.474885  0.606080  0.075392  0.010932   \n",
       "7        0.429255  0.233265  0.254574  0.474885  0.606080  0.075392  0.010932   \n",
       "8        0.430393  0.175945  0.242508  0.475004  0.603977  0.075392  0.010932   \n",
       "9        0.430393  0.175945  0.242508  0.475004  0.603977  0.075392  0.010932   \n",
       "10       0.430393  0.175945  0.242508  0.475004  0.603977  0.075392  0.010932   \n",
       "\n",
       "              SHI      TSEI  0  ...  8  9  10  11  12  13  14  15  16  17  \n",
       "AtomIdx                         ...                                        \n",
       "0        0.169843  0.399595  0  ...  0  0   0   0   0   0   0   0   0   0  \n",
       "1        0.212078  0.460438  0  ...  0  0   0   0   0   0   0   0   0   0  \n",
       "2        0.169843  0.149643  0  ...  0  0   0   0   0   0   0   0   0   0  \n",
       "3        0.214501  0.000000  1  ...  0  0   0   0   0   0   0   0   0   0  \n",
       "4        0.214501  0.000000  1  ...  0  0   0   0   0   0   0   0   0   0  \n",
       "5        0.203784  0.000000  1  ...  0  0   0   0   0   0   0   0   0   0  \n",
       "6        0.230402  0.000000  1  ...  0  0   0   0   0   0   0   0   0   0  \n",
       "7        0.230402  0.000000  1  ...  0  0   0   0   0   0   0   0   0   0  \n",
       "8        0.214501  0.000000  1  ...  0  0   0   0   0   0   0   0   0   0  \n",
       "9        0.203784  0.000000  1  ...  0  0   0   0   0   0   0   0   0   0  \n",
       "10       0.214501  0.000000  1  ...  0  0   0   0   0   0   0   0   0   0  \n",
       "\n",
       "[11 rows x 27 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e09a4220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([220, 27])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "atom_fea = [df[0] for df in res]\n",
    "all_atom_fea = pd.concat(atom_fea)\n",
    "test = torch.from_numpy(np.array(all_atom_fea))\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "546e3d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 27)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_atom_fea.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "350cc182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SB</th>\n",
       "      <th>DB</th>\n",
       "      <th>TB</th>\n",
       "      <th>AB</th>\n",
       "      <th>CB</th>\n",
       "      <th>RB</th>\n",
       "      <th>SN</th>\n",
       "      <th>SA</th>\n",
       "      <th>SS</th>\n",
       "      <th>SR</th>\n",
       "      <th>BO</th>\n",
       "      <th>BL</th>\n",
       "      <th>BDE</th>\n",
       "      <th>BDFE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BondIdx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209400</td>\n",
       "      <td>0.427884</td>\n",
       "      <td>0.326613</td>\n",
       "      <td>0.306577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209438</td>\n",
       "      <td>0.427833</td>\n",
       "      <td>0.326613</td>\n",
       "      <td>0.306577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172765</td>\n",
       "      <td>0.099385</td>\n",
       "      <td>0.394351</td>\n",
       "      <td>0.395220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172765</td>\n",
       "      <td>0.099385</td>\n",
       "      <td>0.394351</td>\n",
       "      <td>0.395220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172765</td>\n",
       "      <td>0.099385</td>\n",
       "      <td>0.394351</td>\n",
       "      <td>0.395220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.165201</td>\n",
       "      <td>0.102334</td>\n",
       "      <td>0.372077</td>\n",
       "      <td>0.372929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.165201</td>\n",
       "      <td>0.102334</td>\n",
       "      <td>0.372077</td>\n",
       "      <td>0.372929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172765</td>\n",
       "      <td>0.099385</td>\n",
       "      <td>0.394351</td>\n",
       "      <td>0.395220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172765</td>\n",
       "      <td>0.099385</td>\n",
       "      <td>0.394351</td>\n",
       "      <td>0.395220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172765</td>\n",
       "      <td>0.099385</td>\n",
       "      <td>0.394351</td>\n",
       "      <td>0.395220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SB   DB   TB   AB   CB   RB   SN   SA   SS   SR        BO        BL  \\\n",
       "BondIdx                                                                         \n",
       "0        1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.209400  0.427884   \n",
       "1        1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.209438  0.427833   \n",
       "2        1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.172765  0.099385   \n",
       "3        1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.172765  0.099385   \n",
       "4        1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.172765  0.099385   \n",
       "...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...       ...   \n",
       "5        1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.165201  0.102334   \n",
       "6        1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.165201  0.102334   \n",
       "7        1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.172765  0.099385   \n",
       "8        1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.172765  0.099385   \n",
       "9        1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.172765  0.099385   \n",
       "\n",
       "              BDE      BDFE  \n",
       "BondIdx                      \n",
       "0        0.326613  0.306577  \n",
       "1        0.326613  0.306577  \n",
       "2        0.394351  0.395220  \n",
       "3        0.394351  0.395220  \n",
       "4        0.394351  0.395220  \n",
       "...           ...       ...  \n",
       "5        0.372077  0.372929  \n",
       "6        0.372077  0.372929  \n",
       "7        0.394351  0.395220  \n",
       "8        0.394351  0.395220  \n",
       "9        0.394351  0.395220  \n",
       "\n",
       "[200 rows x 14 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bond_fea = [df[1] for df in res]\n",
    "all_bond_fea = pd.concat(bond_fea)\n",
    "all_bond_fea = all_bond_fea.drop(['BeginAtomIdx', 'EndAtomIdx'], axis=1)\n",
    "all_bond_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7990693c-8c52-4789-a560-59461ba49ecd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "3 columns passed, passed data had 10 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/uspto/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    905\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_or_indexify_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/uspto/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_validate_or_indexify_columns\u001b[0;34m(content, columns)\u001b[0m\n\u001b[1;32m    954\u001b[0m             raise AssertionError(\n\u001b[0;32m--> 955\u001b[0;31m                 \u001b[0;34mf\"{len(columns)} columns passed, passed data had \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m                 \u001b[0;34mf\"{len(content)} columns\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 3 columns passed, passed data had 10 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2111/1756328097.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0midx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdf_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbegins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mends\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'atomidx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begins'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ends'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mdf_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'atomidx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdf_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/uspto/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    698\u001b[0m                         \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m                         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m                         \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m                     )\n\u001b[1;32m    702\u001b[0m                     mgr = arrays_to_mgr(\n",
      "\u001b[0;32m~/miniconda3/envs/uspto/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/uspto/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m     \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_finalize_columns_and_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/uspto/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0;31m# GH#26429 do not raise user-facing AssertionError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 3 columns passed, passed data had 10 columns"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "begins = []\n",
    "ends = []\n",
    "idx = []\n",
    "for i in range(mol.GetNumBonds()):\n",
    "    bond = mol.GetBondWithIdx(i)\n",
    "    begins.append(bond.GetEndAtomIdx())\n",
    "    ends.append(bond.GetBeginAtomIdx())\n",
    "    idx.append(i)\n",
    "\n",
    "df_idx = pd.DataFrame([begins, ends], columns=['atomidx', 'begins', 'ends'])\n",
    "df_idx.set_index('atomidx')\n",
    "df_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d8c216d-fb9b-4933-9aba-69e2f183dfe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4587eb17-90fc-406c-aa39-6095f166e5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bond.GetBeginAtomIdx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4987ba0-3fc0-4218-9101-7d1e84ed7fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd1a448-91a8-4dd5-b327-e585843cf15d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00529544-ab10-4747-a5d6-c1cdcffd54e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for bond in mol.GetBonds():\n",
    "    print(bond.GetIdx())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec6a128b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bond.GetIdx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f15c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "007fce85138c9462f0c1b8a135b4ca467b2530a781393e5d0a3b48caa18f0882"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('uspto')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
